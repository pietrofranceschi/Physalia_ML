{
 "cells": [
  {
   "cell_type": "raw",
   "id": "auburn-macedonia",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Random Forest\"\n",
    "author: \"Filippo Biscarini\"\n",
    "date: \"7/9/2020\"\n",
    "output: html_document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-collect",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "library(\"knitr\")\n",
    "# library(\"caret\")       # for general model fitting\n",
    "library(\"rpart\")       # for fitting decision trees\n",
    "library(\"ipred\")  \n",
    "library(\"foreach\")     # for parallel processing with for loops\n",
    "library(\"ggplot2\")\n",
    "library(\"rpart.plot\")\n",
    "library(\"doParallel\")  # for parallel backend to foreach\n",
    "library(\"data.table\")\n",
    "library(\"tidymodels\")\n",
    "library(\"randomForest\")\n",
    "\n",
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-dodge",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "For this practical session on logistic regression we are using a dataset on the relationship between cleft lip in dogs (Nova Scotia Duck Tolling Retriever, NSDTR) and SNP genotypes ([data](https://datadryad.org/stash/dataset/doi:10.5061/dryad.j8r8q); [paper](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1005059)).\n",
    "\n",
    "The public dataset downloaded from Dryad is a *Plink* `.tped/.tfam` file. The data have been preprocessed:\n",
    "\n",
    "- filtered (SNP quality, call-rate, MAF)\n",
    "- imputed (imputation of missing genotypes using LHCI: localised haplotype-clustering imputation)\n",
    "- selected (only SNPs on chromosomes 25, 26, 27, 28, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs <- fread(\"../data/dogs_imputed.raw\")\n",
    "dogs <- dogs %>%\n",
    "  select(-c(IID,FID,PAT,MAT,SEX))\n",
    "\n",
    "dogs$PHENOTYPE = dogs$PHENOTYPE-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-season",
   "metadata": {},
   "source": [
    "## Trees and bagging\n",
    "\n",
    "#### Classification tree\n",
    "\n",
    "Let's start with a classification tree. We split the data in training and testing sets:\n",
    "\n",
    "- function `rpart` (from the *rpart* package)\n",
    "- method = \"class\" (classification)\n",
    "- `minsplit`: minimum number of observations (records) in a split (splits with fewer than 3 records will not be considered/attempted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-caution",
   "metadata": {
    "name": "subset",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "seed = 157\n",
    "set.seed(seed)\n",
    "\n",
    "##Training data\n",
    "n = nrow(dogs) ## sample size\n",
    "n_training = round(0.75*n,0)\n",
    "n_test = n - n_training\n",
    "training_records <- sample(n,n_training)\n",
    "x_train <- dogs[training_records,]\n",
    "x_test <- dogs[-training_records,-1]\n",
    "y_test <- as.factor(dogs[-training_records,]$PHENOTYPE)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "table(x_train$PHENOTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-soldier",
   "metadata": {},
   "source": [
    "Then fit the classification tree model to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-furniture",
   "metadata": {
    "name": "classification_tree"
   },
   "outputs": [],
   "source": [
    "##Model without bagging\n",
    "no_bag_model <- rpart(PHENOTYPE ~ ., data = x_train, method = \"class\", control = rpart.control(minsplit = 3))\n",
    "\n",
    "rpart.plot(no_bag_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-murray",
   "metadata": {},
   "source": [
    "In the *tree-plot* we see:\n",
    "\n",
    "- the **classification**\n",
    "- the modelled class probability $\\rightarrow$ $P(y=1|x)$ (i.e. the probability of the class conditioned on the node)\n",
    "- the percentage of observations used at that node\n",
    "\n",
    "With the trained model we can make predictions in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-johnson",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "predictions <- predict(no_bag_model, x_test, type = \"class\")\n",
    "table(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-watts",
   "metadata": {},
   "source": [
    "#### Bagging\n",
    "\n",
    "We now take 10 bootstrapped samples of the data, and fit a classification tree to each sample. We use OOB observations to measure the prediction error.\n",
    "At each bagging replicate (bootstrapped sample) typically $1/3$ of the observations are not used for training (out-of-bag -OOB- observations), and can naturally be used to measure the prediction error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-silver",
   "metadata": {
    "name": "bagging"
   },
   "outputs": [],
   "source": [
    "n_model = 10\n",
    "bagged_models <- list()\n",
    "oob <- list()\n",
    "for (i in 1:n_model) {\n",
    "  \n",
    "  records = seq(1,nrow(dogs))\n",
    "  new_sample <- sample(records, size=nrow(dogs), replace=TRUE) ## bootstrapping here!!\n",
    "  oob <- c(oob, list(records[!(records %in% new_sample)]))\n",
    "  bagged_models <- c(\n",
    "    bagged_models,\n",
    "    list(rpart(PHENOTYPE ~ ., dogs[new_sample,], control = rpart.control(minsplit=3))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Getting estimate from the bagged model\n",
    "oob_results = data.frame(\"rep\"=NULL, \"error\"=NULL)\n",
    "i = 1\n",
    "for (bag_model in bagged_models) {\n",
    "\n",
    "  preds = predict(bag_model, dogs[oob[[i]],-1]) ## predict by applying the trained model on the OBB data\n",
    "  obs = dogs$PHENOTYPE[oob[[i]]]\n",
    "  oob_results = rbind.data.frame(oob_results, data.frame(\"rep\"=i, \"error\"=1-sum(preds == obs)/length(preds))) ## check obs == preds\n",
    "  i = i+1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "kable(oob_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paste(\"average OOB error:\" , mean(oob_results$error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-association",
   "metadata": {},
   "source": [
    "Alternatively, we can proceed with splitting the data in training and testing sets, fit the classification trees to bootstrapped replicates of the training data, and then estimate the error rate on the test data.\n",
    "\n",
    "Also here we will have OOB observations, but the error rate in this case would tend to be overestimated since the training set is smaller than the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-criminal",
   "metadata": {
    "name": "bagging2"
   },
   "outputs": [],
   "source": [
    "n_model = 10\n",
    "bagged_models <- list()\n",
    "oob <- list()\n",
    "for (i in 1:n_model) {\n",
    "  \n",
    "  new_sample <- sample(training_records, size=length(training_records), replace=TRUE)\n",
    "  oob <- c(oob, list(training_records[!(training_records %in% new_sample)]))\n",
    "  bagged_models <- c(\n",
    "    bagged_models,\n",
    "    list(rpart(PHENOTYPE ~ ., dogs[new_sample,], control = rpart.control(minsplit=3))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Getting estimate from the bagged model\n",
    "bagged_result = NULL\n",
    "i = 0\n",
    "for (bag_model in bagged_models) {\n",
    " \n",
    "  if (is.null(bagged_result)) {\n",
    "    bagged_result = predict(bag_model, x_test)\n",
    "  } else {\n",
    "   bagged_result=(i*bagged_result+predict(bag_model, x_test))/(i+1) ## % of times each observation was classified as 1\n",
    "  }\n",
    "i = i+1\n",
    "}\n",
    "\n",
    "\n",
    "diff = abs(bagged_result - (as.integer(y_test)-1)) ## absolute differences between predictions and observations (averaged over the n replicates of the model)\n",
    "error = sum(n_model*diff)/(length(y_test)*n_model) ## average error over number of predictions (size of test set time n. of replicates)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-right",
   "metadata": {},
   "source": [
    "Total test error rate is `r error`.\n",
    "The breakdown in FPR and FNR is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "breeding-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 Ã— 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>obs</th><th scope=col>N</th><th scope=col>err</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>27</td><td>0.003703704</td></tr>\n",
       "\t<tr><td>1</td><td> 4</td><td>0.000000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 Ã— 3\n",
       "\\begin{tabular}{lll}\n",
       " obs & N & err\\\\\n",
       " <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 27 & 0.003703704\\\\\n",
       "\t 1 &  4 & 0.000000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 Ã— 3\n",
       "\n",
       "| obs &lt;dbl&gt; | N &lt;int&gt; | err &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 0 | 27 | 0.003703704 |\n",
       "| 1 |  4 | 0.000000000 |\n",
       "\n"
      ],
      "text/plain": [
       "  obs N  err        \n",
       "1 0   27 0.003703704\n",
       "2 1    4 0.000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- data.frame(\"pred\"=bagged_result,\"obs\"=as.integer(y_test)-1)\n",
    "df %>%\n",
    "  group_by(obs) %>%\n",
    "  summarise(N=n(),err=sum(10*abs(pred-obs))/(N*10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-supervisor",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "We can now make the next step from bagging (averaging over bootstrapped trees) to Random Forest (adding randomly sampled subsets of features to bootstrapped data):\n",
    "\n",
    "- first, split the data in training and test sets (we keep y and x separate here)\n",
    "- then we fit a RF model to the training set, without tuning any hyperparameters (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-employment",
   "metadata": {
    "name": "rf",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "##Training data\n",
    "n = nrow(dogs) ## sample size\n",
    "n_training = round(0.8*n,0)\n",
    "n_test = n - n_training\n",
    "training_records <- sample(n,n_training)\n",
    "x_train <- as.matrix(dogs[training_records,-1])\n",
    "y_train <- as.factor(dogs[training_records,]$PHENOTYPE)\n",
    "x_test <- as.matrix(dogs[-training_records,-1])\n",
    "y_test <- as.factor(dogs[-training_records,]$PHENOTYPE)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dogs <- randomForest(x = x_train, y = y_train, ntree = 10)\n",
    "rf.dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-petersburg",
   "metadata": {},
   "source": [
    "#### Let's tune it up a little!\n",
    "\n",
    "Now we use a convenient built-in function to tune hyperparameters in random forest: the `tuneRF` function:\n",
    "\n",
    "- we tune just the number of variables to sample in each tree, `mtry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf <- tuneRF(x_train, y_train, mtryStart = 25, ntreeTry=50, stepFactor=1.5, improve=0.01,\n",
    "       trace=TRUE, plot=TRUE)\n",
    "\n",
    "head(tuned_rf)\n",
    "num_row <- which(tuned_rf[,2] == min(tuned_rf[,2])) ## row corresponding to min OOB error\n",
    "num_vars <- tuned_rf[num_row,1]  ## mtry value corresponding to min OOB error\n",
    "print(num_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-champagne",
   "metadata": {},
   "source": [
    "Now we fit a final RF model with the tuned value for `mtry` (number of variables subsampled in each tree), and build a small forest with 100 trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dogs <- randomForest(x = x_train, y = y_train, ntree = 100, mtry = num_vars, importance = TRUE)\n",
    "\n",
    "imp <- as.data.frame(importance(rf.dogs))\n",
    "summary(imp)\n",
    "top_vars <- imp %>%\n",
    "  arrange(desc(MeanDecreaseGini)) %>%\n",
    "  top_n(20) %>%\n",
    "  select(MeanDecreaseGini) %>%\n",
    "  mutate(name_var = gsub(\"\\\\_.*$\",\"\",row.names(.)))\n",
    "\n",
    "top_vars$name_var <- factor(top_vars$name_var, levels = rev(top_vars$name_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-finish",
   "metadata": {},
   "source": [
    "#### Variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-fault",
   "metadata": {
    "name": "varimp"
   },
   "outputs": [],
   "source": [
    "p <- ggplot(top_vars, aes(x=name_var,y=MeanDecreaseGini)) + geom_bar(stat=\"identity\")\n",
    "p <- p + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n",
    "p <- p + coord_flip()\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-shower",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs <- predict(rf.dogs, newdata = x_test, type = \"prob\")\n",
    "predictions <- ifelse(probs[,\"1\"] > 0.5, 1, 0 )\n",
    "table(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-former",
   "metadata": {
    "label": "roc",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "library(\"ROCit\")\n",
    "\n",
    "load(\"ROClogit.RData\")\n",
    "load(\"ROClasso.RData\")\n",
    "\n",
    "ROCit_rf <- rocit(score=probs[,\"1\"],class=y_test)\n",
    "plot(ROCit_rf, col = c(1,\"gray50\"), \n",
    "     legend = FALSE, YIndex = FALSE)\n",
    "lines(ROCit_lasso$TPR~ROCit_lasso$FPR,col = 2, lwd = 2)\n",
    "lines(ROCit_logit$TPR~ROCit_logit$FPR,col = 3, lwd = 3)\n",
    "legend(\"bottomright\", col = c(1,2,3),\n",
    "       c(\"RF\",\"Lasso\", \"Logistic regression\"), lwd = 2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "label,tags,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
