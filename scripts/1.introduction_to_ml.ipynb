{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dominican-inclusion",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Introduction to Machine Learning for predictions\"\n",
    "author: \"Filippo Biscarini\"\n",
    "date: \"18/03/2021\"\n",
    "output: html_document\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-curtis",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)\n",
    "library(\"knitr\")\n",
    "library(\"dplyr\")\n",
    "library(\"plotly\")\n",
    "library(\"ggplot2\")\n",
    "library(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-survey",
   "metadata": {},
   "source": [
    "## 1.1 Linear regression: a basic model for parameter estimation\n",
    "\n",
    "Here we look more in detail to how the estimation of model parameters works. <br> We have a generating model of the following form:\n",
    "\n",
    "$$\n",
    "y = 1.25 \\cdot x\n",
    "$$\n",
    "\n",
    "The **true** $\\theta$ (model parameter: slope) is therefore $1.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-tomorrow",
   "metadata": {
    "name": "lin_reg"
   },
   "outputs": [],
   "source": [
    "lin_reg <- function(x) 1.25*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-mississippi",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "x = 1\n",
    "y = lin_reg(x)\n",
    "print(paste(\"y as function of x=1 in the model above:\",y))\n",
    "\n",
    "## now apply the function to a bunch of data\n",
    "x = seq(-5,+5,0.5) ## independent variable\n",
    "y = lin_reg(x) ## dependent variable\n",
    "\n",
    "kable(data.frame(\"x\" = x, \"y\" = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-monday",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "p <- ggplot(data = data.frame(x = 0), mapping = aes(x = x))\n",
    "p <- p + stat_function(fun = lin_reg) + xlim(-5,6)\n",
    "p <- p + theme(axis.title.y = element_text(angle=0, vjust = 0.5))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-bullet",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "\n",
    "For linear regression (simple or multiple, as long as $n > p$), the least squares method can be used, where the residual sum of squares is minimised through differentiation of vector and matrix expressions (linear algebra $\\rightarrow$ *normal equations*).\n",
    "\n",
    "However, from the perspective of machine learning a different approach is taken. First, a **loss function** is chosen: a common choice for (multiple) linear regression is the **normalised squared error function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function <- function(x,beta) {\n",
    "  \n",
    "  n = length(x)\n",
    "  y = lin_reg(x)\n",
    "  normalised_squared_error = sum((y - beta*x)^2)/(2*n)\n",
    "  \n",
    "  return(normalised_squared_error)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-national",
   "metadata": {},
   "source": [
    "We then calculate the loss function for different values of the parameter(s) to estimate.\n",
    "We take 11 datapoints (from 0 to 10) for our linear regression model and try different values for beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- seq(0,10,0.25)\n",
    "beta <- seq(0.25,2.25,0.05)\n",
    "\n",
    "cost <- sapply(beta, function(z) loss_function(x,z))\n",
    "res <- data.frame(\"x\" = x, \"beta\" = beta, \"loss\" = cost)\n",
    "beta_min = res[which.min(res$loss),\"beta\"]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paste(\"parameter value for which the cost function is minimised:\", beta_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-documentation",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "pressure",
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "plot(beta,cost, type=\"l\",xlab = \"Values for parameter beta\", ylab = \"Value for loss function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-subcommittee",
   "metadata": {},
   "source": [
    "Note: sometimes the term **loss function** is used to define the individual loss (each single record, i.e. $(y_i-\\hat{y_i})^2$) and the term **cost function** is used for the summ of individual losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-proof",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "Try to estimate your own model coefficient:\n",
    "\n",
    "1. Create your generating (true) model (dare try with the intercept, too?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-massage",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "lin_reg.1 <- function() {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-planet",
   "metadata": {},
   "source": [
    "2. Define your own loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-childhood",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "loss_function.1 <- function() {\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-liberal",
   "metadata": {},
   "source": [
    "3. Create your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-wallace",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "x <- seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-recruitment",
   "metadata": {},
   "source": [
    "4. Choose a set of values for $\\beta$ to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-links",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "beta0 = \n",
    "beta1 = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-mounting",
   "metadata": {},
   "source": [
    "5. Calculate the values for the loss function and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-copying",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "cost =\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-glucose",
   "metadata": {},
   "source": [
    "6. Plot the cost function vs values of the parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-meeting",
   "metadata": {
    "lines_to_next_cell": 2,
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "library(\"plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-kansas",
   "metadata": {},
   "source": [
    "## 1.2 Linear regression: measuring performance\n",
    "\n",
    "In practice, we are not going to manually minimise the loss function to estimate model parameters for our predictive machine: instead, higher-level *R* functions are used, like `lm()`.\n",
    "\n",
    "An important aspect of predictive statistics is to measure the performance of the developed predictive model (predictive machine).\n",
    "\n",
    "Let's start by using an example dataset from base R: the ChickWeight dataset, with weight and age of chicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data(ChickWeight) ##\n",
    "dataset <- rename(ChickWeight, y = weight, x = Time) %>% select(y,x)\n",
    "kable(head(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-internet",
   "metadata": {},
   "source": [
    "We now fit a simple linear regression model:\n",
    "\n",
    "$$\n",
    "y = \\mu + \\beta \\cdot x + e\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- lm(y ~ x, data = dataset)\n",
    "coef(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(dataset, aes(x = x, y = y)) + geom_jitter() + geom_smooth(method = \"lm\", se = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-diversity",
   "metadata": {},
   "source": [
    "We now have all the ingredients to obtain predictions: either by explicitly using the estimated coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions <- dataset$x*coef(fit)[2] + coef(fit)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-spread",
   "metadata": {},
   "source": [
    "or by using the *R* `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?predict\n",
    "predictions <- predict(fit, newdata = dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-beatles",
   "metadata": {},
   "source": [
    "The two approaches are obviously equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance <- predict(fit, newdata = dataset) == dataset$x*coef(fit)[2] + coef(fit)[1]\n",
    "sum(concordance)/length(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-found",
   "metadata": {},
   "source": [
    "The predict function is more flexible and can for instance also give us a confidence interval for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(fit, newdata = dataset, interval = \"confidence\") %>%\n",
    "  head() %>%\n",
    "  kable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-product",
   "metadata": {},
   "source": [
    "Finally, we can plot predictions against observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-emerald",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dataset$predictions <- predictions\n",
    "plot(dataset$y, dataset$predictions, xlab = \"observations\", ylab = \"predictions\")\n",
    "#abline(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-rainbow",
   "metadata": {},
   "source": [
    "Besides visualizing how predictions relate to observations, we need also to measure (quantify) the predictive performance of the model.\n",
    "\n",
    "Several metrics exist for regression problems. Here we list a few of the most commonly used.\n",
    "\n",
    "1. **MSE** (mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse <- function(y,y_hat) {\n",
    "  \n",
    "  n = length(y)\n",
    "  se = sum((y-y_hat)^2)\n",
    "  mse = se/n\n",
    "  \n",
    "  return(mse)\n",
    "}\n",
    "\n",
    "error = mse(y = dataset$y, y_hat = predictions)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-settle",
   "metadata": {},
   "source": [
    "The MSE is **`r round(error,3)`**.\n",
    "\n",
    "2. **RMSE** (root mean squared error): this is on the same scale as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(error)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cause",
   "metadata": {},
   "source": [
    "The RMSE is **`r round(rmse,3)`**.\n",
    "\n",
    "3. **MAE** (mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae <- function(y,y_hat) {\n",
    "  \n",
    "  n = length(y)\n",
    "  se = sum(abs(y-y_hat))\n",
    "  mae = se/n\n",
    "  \n",
    "  return(mae)\n",
    "}\n",
    "\n",
    "error = mae(y = dataset$y, y_hat = predictions)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-headquarters",
   "metadata": {},
   "source": [
    "The MAE is **`r round(error,3)`**.\n",
    "\n",
    "The we have correlations:\n",
    "\n",
    "4. **Pearson's linear** correlation coefficient\n",
    "5. **Spearman's rank** correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pearson = cor(dataset$y, predictions, method = \"pearson\")\n",
    "r_spearman = cor(dataset$y, predictions, method = \"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_pearson)\n",
    "print(r_spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-wireless",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "\n",
    "Generate a dataset, fit a linear model and measure the accuracy of predictions:\n",
    "\n",
    "1. you can choose one of the many built-in R datasets, using the function `data()`\n",
    "2. or you can generate a dataset (e.g. sampling from a Gaussian distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(dataset, aes(x = x, y = y)) + geom_jitter() + geom_smooth(method = \"lm\", formula = y ~ poly(x,2), se = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-transition",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "#data()\n",
    "\n",
    "#y <- rnorm(n = 100, mean = 0, sd = 1)\n",
    "#x <- rnorm(n = 100, mean = 0, sd = 1)\n",
    "\n",
    "y = NULL # target variable\n",
    "x = NULL # feature 1\n",
    "z = NULL # feature 2 (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-symposium",
   "metadata": {},
   "source": [
    "2. Fit a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-customer",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "# fit <- lm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-survivor",
   "metadata": {},
   "source": [
    "3. Obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-renewal",
   "metadata": {
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "# predictions <- predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-manor",
   "metadata": {},
   "source": [
    "4. Plot observations vs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p <- ggplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-directory",
   "metadata": {},
   "source": [
    "5. Choose a metric to measure the accuracy of predictions (performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-compromise",
   "metadata": {
    "lines_to_next_cell": 0,
    "results": "asis"
   },
   "outputs": [],
   "source": [
    "# metric = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-practitioner",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "results,tags,name,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
